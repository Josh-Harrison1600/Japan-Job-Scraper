run-name: Run scraper daily
on:
  schedule:
    - cron: "0 18 * * *"
  workflow_dispatch:

jobs:
  schedule-job:
    runs-on: ubuntu-latest
    permissions: write-all
    steps:
      - name: checkout repo content
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
      - name: setup python
        uses: actions/setup-python@v2
        with:
          python-version: 3.12.4

      - name: install deps
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 python-dotenv
      - name: run the scrapers and send the email if new jobs are found
        env:
          APP_PASSWORD: ${{ secrets.APP_PASSWORD }}
        run: |
          python Main.py

      - name: save results of the scrapers
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add .
          git commit -m "Update job listings" || echo "No changes to commit"
          git pull --rebase --autostash origin main
          git push origin main
